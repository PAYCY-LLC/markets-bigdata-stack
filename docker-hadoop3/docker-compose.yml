version: '3.7'

services:
    #  ------- Hadoop ----------------
    namenode:
        container_name: hadoop-namenode
        image: timveil/docker-hadoop-namenode:3.2.x
        volumes:
            - namenode:/hadoop/dfs/name
        environment:
            - CLUSTER_NAME=bigdata1
        env_file:
            - ./config/hadoop-core.env
        ports:
            - '9870:9870'
        networks:
            - base_net

    datanode:
        container_name: hadoop-datanode
        image: timveil/docker-hadoop-datanode:3.2.x
        volumes:
            - datanode:/hadoop/dfs/data
        env_file:
            - ./config/hadoop-core.env
        environment:
            SERVICE_PRECONDITION: 'namenode:9870'
        ports:
            - '9864:9864'
        networks:
            - base_net

    # -------- Hive --------------------------------

    hive-server:
        container_name: hive-server
        build:
          context: './images/hive-base/'
          dockerfile: 'Dockerfile'
        restart: always
        env_file:
          - ./config/hadoop-core.env
          - ./config/hive.env
        environment:
            HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: 'jdbc:postgresql://hive-metastore/metastore'
            SERVICE_PRECONDITION: 'hive-metastore:9083'
            HDFS_CONF_fs_s3a_access_key: ${S3_ACCESS_KEY}
            HDFS_CONF_fs_s3a_secret_key: ${S3_SECRET_KEY}
        command:
           -  /run.sh
        ports:
            - '10000:10000'
            - '10002:10002'
        networks:
            - base_net

    hive-metastore:
        container_name: hive-metastore
        build:
          context: './images/hive-base/'
          dockerfile: 'Dockerfile'
        restart: always
        env_file:
            - ./config/hadoop-core.env
            - ./config/hive.env
            - ./config/hive-metastore.env
        command: /opt/hive/bin/hive --service metastore
        environment:
            SERVICE_PRECONDITION: 'namenode:9870 datanode:9864 hive-metastore-db:5432'
            HDFS_CONF_fs_s3a_access_key: ${S3_ACCESS_KEY}
            HDFS_CONF_fs_s3a_secret_key: ${S3_SECRET_KEY}
        ports:
            - '9083:9083'
        networks:
            - base_net

    hive-metastore-db:
      container_name: hive-metastore-db
      hostname: hive-metastore-db
      image: timveil/docker-hadoop-hive-metastore-db:3.1.x
      networks:
          - base_net

    # --------- Trino -----------------
    trino-coordinator:
        container_name: trino-coordinator
        build:
          context: './images/trino/'
          dockerfile: 'Dockerfile'
        restart: always
        ports:
            - '8080:8080'
        environment:
            S3_ACCESS_KEY: ${S3_ACCESS_KEY}
            S3_SECRET_KEY: ${S3_SECRET_KEY}
        volumes:
            - ./config/trino/coordinator:/opt/trino/etc
        networks:
            - base_net

    # trino-worker:
    #     container_name: trino-worker
    #     build:
    #       context: './images/trino/'
    #       dockerfile: 'Dockerfile'
    #     restart: always
    #     environment:
    #         S3_ACCESS_KEY: ${S3_ACCESS_KEY}
    #         S3_SECRET_KEY: ${S3_SECRET_KEY}
    #     volumes:
    #         - ./config/trino/worker:/opt/trino/etc
    #     networks:
    #         - base_net

    #  ------- Minio ----------------
    minio:
        container_name: minio
        image: minio/minio
        restart: always
        ports:
            - '9000:9000'
        environment:
          MINIO_ACCESS_KEY: ${S3_ACCESS_KEY}
          MINIO_SECRET_KEY: ${S3_SECRET_KEY}
        volumes:
            - minio:/data
        command: server /data
        networks:
            - base_net

networks:
    base_net:
        name: bigdatanet

volumes:
    datanode:
    namenode:
    minio:
